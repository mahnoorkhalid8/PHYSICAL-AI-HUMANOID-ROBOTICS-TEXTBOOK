---
id: gpt-integration-conversational
title: GPT Integration for Conversational AI
---

# GPT Integration for Conversational AI

Integrating large language models for natural language interaction with robots.

## Introduction to Conversational AI in Robotics

Conversational AI enables natural human-robot interaction through natural language processing. By integrating large language models like GPT into robotic systems, we can create more intuitive and accessible interfaces that allow users to communicate with robots using everyday language rather than complex programming commands.

## Architecture of GPT-Robot Integration

The conversational AI system typically consists of several components:

1. **Speech Recognition**: Converting spoken language to text
2. **Language Understanding**: Interpreting the meaning of user input
3. **Dialog Management**: Maintaining conversation context and state
4. **Action Execution**: Translating language to robot actions
5. **Response Generation**: Creating natural language responses
6. **Speech Synthesis**: Converting text responses to speech

## Python Implementation for GPT Integration

```python
import rclpy
from rclpy.node import Node
from std_msgs.msg import String
from sensor_msgs.msg import LaserScan
from geometry_msgs.msg import Twist
import openai
import json
import asyncio
import speech_recognition as sr
import pyttsx3
from datetime import datetime

class GPTConversationalRobot(Node):
    def __init__(self):
        super().__init__('gpt_conversational_robot')

        # Publishers and subscribers
        self.cmd_vel_publisher = self.create_publisher(Twist, '/cmd_vel', 10)
        self.speech_publisher = self.create_publisher(String, '/robot_speech', 10)
        self.command_publisher = self.create_publisher(String, '/high_level_commands', 10)
        self.lidar_subscriber = self.create_subscription(
            LaserScan, '/scan', self.lidar_callback, 10
        )

        # Initialize speech recognition and synthesis
        self.recognizer = sr.Recognizer()
        self.microphone = sr.Microphone()
        self.tts_engine = pyttsx3.init()

        # Initialize OpenAI client
        # openai.api_key = "your-api-key-here"  # Set your API key appropriately

        # Conversation context
        self.conversation_history = []
        self.robot_capabilities = [
            "navigation", "object manipulation", "environment monitoring",
            "conversation", "task execution", "status reporting"
        ]

        # Robot state
        self.robot_state = {
            'location': 'unknown',
            'battery_level': 100,
            'current_task': 'idle',
            'obstacles_detected': False
        }

        # Setup speech recognition parameters
        with self.microphone as source:
            self.recognizer.adjust_for_ambient_noise(source)

        self.get_logger().info('GPT Conversational Robot initialized')

    def lidar_callback(self, msg):
        """Process LIDAR data to update robot state"""
        # Check for nearby obstacles
        min_distance = min(msg.ranges)
        self.robot_state['obstacles_detected'] = min_distance < 1.0  # 1 meter threshold

    def listen_for_speech(self):
        """Listen for user speech and convert to text"""
        try:
            with self.microphone as source:
                self.get_logger().info("Listening for speech...")
                audio = self.recognizer.listen(source, timeout=5.0, phrase_time_limit=5.0)

            # Convert speech to text
            text = self.recognizer.recognize_google(audio)
            self.get_logger().info(f"Heard: {text}")
            return text
        except sr.WaitTimeoutError:
            self.get_logger().info("No speech detected")
            return None
        except sr.UnknownValueError:
            self.get_logger().info("Could not understand audio")
            return None
        except Exception as e:
            self.get_logger().error(f"Speech recognition error: {e}")
            return None

    def generate_response_with_gpt(self, user_input):
        """Generate response using GPT model"""
        # Build context for the conversation
        context = self.build_conversation_context(user_input)

        # Prepare the prompt for GPT
        prompt = f"""
        You are a helpful humanoid robot assistant. Your capabilities include: {', '.join(self.robot_capabilities)}.
        Current robot state: {json.dumps(self.robot_state)}

        Previous conversation:
        {context}

        User says: "{user_input}"

        Respond naturally and helpfully. If the user requests an action you can perform,
        describe what you will do and then provide the action in JSON format.

        Example response format:
        "I can help you with that. I will navigate to the kitchen."
        {{"action": "navigate_to_kitchen", "parameters": {{"location": "kitchen"}}}}
        """

        try:
            # In a real implementation, this would call the OpenAI API
            # response = openai.ChatCompletion.create(
            #     model="gpt-3.5-turbo",
            #     messages=[{"role": "user", "content": prompt}],
            #     max_tokens=200,
            #     temperature=0.7
            # )
            # gpt_response = response.choices[0].message.content.strip()

            # For demonstration, simulate GPT response
            gpt_response = self.simulate_gpt_response(user_input)

            # Parse the response to extract action if present
            response_text, action = self.parse_gpt_response(gpt_response)

            # Update conversation history
            self.conversation_history.append({
                'role': 'user',
                'content': user_input
            })
            self.conversation_history.append({
                'role': 'assistant',
                'content': response_text
            })

            return response_text, action

        except Exception as e:
            self.get_logger().error(f"GPT API error: {e}")
            fallback_response = f"I'm sorry, I'm having trouble processing that request. Could you please repeat it?"
            return fallback_response, None

    def simulate_gpt_response(self, user_input):
        """Simulate GPT response for demonstration purposes"""
        user_input_lower = user_input.lower()

        if 'hello' in user_input_lower or 'hi' in user_input_lower:
            return 'Hello! I am your robotic assistant. How can I help you today?'
        elif 'how are you' in user_input_lower:
            return 'I am functioning well, thank you for asking! How can I assist you?'
        elif 'move' in user_input_lower or 'go' in user_input_lower or 'navigate' in user_input_lower:
            location = 'kitchen' if 'kitchen' in user_input_lower else 'living room'
            return f'I can help you with that. I will navigate to the {location}. {"{"}"action": "navigate", "parameters": {"{"}"location": "{location}{"}"}{"}"}'
        elif 'stop' in user_input_lower:
            return f'I will stop moving. {"{"}"action": "stop", "parameters": {"{"}"}{"}"}'
        elif 'battery' in user_input_lower or 'power' in user_input_lower:
            battery_level = self.robot_state['battery_level']
            return f'My battery level is {battery_level}%. Should I return to my charging station?'
        else:
            return f'I understand you said: "{user_input}". How can I assist you further?'

    def parse_gpt_response(self, gpt_response):
        """Parse GPT response to extract text and action"""
        # Look for JSON action in the response
        import re
        json_match = re.search(r'\{.*\}', gpt_response, re.DOTALL)

        if json_match:
            json_str = json_match.group()
            try:
                action = json.loads(json_str)
                # Extract text before and after JSON
                parts = gpt_response.split(json_str)
                response_text = parts[0].strip()
                if response_text.endswith('.'):
                    response_text = response_text[:-1].strip()
                return response_text, action
            except json.JSONDecodeError:
                # If JSON parsing fails, return full text and no action
                return gpt_response, None
        else:
            # No action found, return text only
            return gpt_response, None

    def build_conversation_context(self, current_input):
        """Build context from conversation history"""
        context = ""
        recent_history = self.conversation_history[-5:]  # Last 5 exchanges

        for exchange in recent_history:
            role = "User" if exchange['role'] == 'user' else "Robot"
            context += f"{role}: {exchange['content']}\n"

        return context

    def execute_action(self, action):
        """Execute the action returned by GPT"""
        if not action:
            return

        action_type = action.get('action', 'unknown')
        parameters = action.get('parameters', {})

        self.get_logger().info(f'Executing action: {action_type} with params: {parameters}')

        if action_type == 'navigate':
            location = parameters.get('location', 'unknown')
            self.navigate_to_location(location)
        elif action_type == 'stop':
            self.stop_robot()
        elif action_type == 'report_status':
            self.report_robot_status()
        elif action_type == 'charge_battery':
            self.navigate_to_charging_station()
        else:
            self.get_logger().info(f'Unknown action: {action_type}')

    def navigate_to_location(self, location):
        """Navigate to a specified location"""
        # In a real implementation, this would use navigation2
        # For demonstration, we'll just log the action
        self.get_logger().info(f'Navigating to {location}')

        # Publish a simple velocity command for demonstration
        cmd = Twist()
        cmd.linear.x = 0.5  # Move forward at 0.5 m/s
        cmd.angular.z = 0.0  # No rotation
        self.cmd_vel_publisher.publish(cmd)

        # In a real system, you would use navigation2 with goal poses
        # self.navigation_client.goToPose(goal_pose)

    def stop_robot(self):
        """Stop the robot's movement"""
        cmd = Twist()
        cmd.linear.x = 0.0
        cmd.angular.z = 0.0
        self.cmd_vel_publisher.publish(cmd)
        self.get_logger().info('Robot stopped')

    def report_robot_status(self):
        """Report current robot status"""
        status_msg = String()
        status_msg.data = f"I am currently at {self.robot_state['location']}. Battery level: {self.robot_state['battery_level']}%. Current task: {self.robot_state['current_task']}."
        self.speech_publisher.publish(status_msg)

    def navigate_to_charging_station(self):
        """Navigate to charging station"""
        self.get_logger().info('Navigating to charging station')
        # Implementation would depend on navigation system

    def speak_response(self, response_text):
        """Convert text response to speech"""
        self.get_logger().info(f'Speaking: {response_text}')

        # Publish to speech topic
        speech_msg = String()
        speech_msg.data = response_text
        self.speech_publisher.publish(speech_msg)

        # Also use text-to-speech engine
        self.tts_engine.say(response_text)
        self.tts_engine.runAndWait()

    def run_conversation_loop(self):
        """Main conversation loop"""
        self.get_logger().info('Starting conversation loop...')

        while rclpy.ok():
            try:
                # Listen for user input
                user_input = self.listen_for_speech()

                if user_input:
                    # Generate response with GPT
                    response_text, action = self.generate_response_with_gpt(user_input)

                    # Speak the response
                    self.speak_response(response_text)

                    # Execute any actions
                    if action:
                        self.execute_action(action)

                # Small delay to prevent excessive CPU usage
                rclpy.spin_once(self, timeout_sec=0.1)

            except KeyboardInterrupt:
                self.get_logger().info('Conversation loop interrupted')
                break
            except Exception as e:
                self.get_logger().error(f'Error in conversation loop: {e}')
                continue

class GPTConversationalNode(Node):
    def __init__(self):
        super().__init__('gpt_conversation_node')

        # Create the main conversational robot
        self.robot = GPTConversationalRobot()

        # Timer for conversation loop
        self.conversation_timer = self.create_timer(0.1, self.conversation_callback)
        self.processing = False

    def conversation_callback(self):
        """Timer callback for conversation processing"""
        if not self.processing:
            self.processing = True
            try:
                # Check for speech input
                user_input = self.robot.listen_for_speech()

                if user_input:
                    # Generate and speak response
                    response_text, action = self.robot.generate_response_with_gpt(user_input)
                    self.robot.speak_response(response_text)

                    # Execute actions if any
                    if action:
                        self.robot.execute_action(action)

            except Exception as e:
                self.get_logger().error(f'Error in conversation: {e}')
            finally:
                self.processing = False

def main(args=None):
    rclpy.init(args=args)

    # Create and run the GPT conversational node
    conversation_node = GPTConversationalNode()

    try:
        # Run the conversation loop
        rclpy.spin(conversation_node)
    except KeyboardInterrupt:
        pass
    finally:
        conversation_node.destroy_node()
        rclpy.shutdown()

if __name__ == '__main__':
    main()
```

## Advanced Conversational Features

### Multi-turn Dialog Management
```python
class DialogManager:
    def __init__(self):
        self.conversation_state = {}
        self.active_intents = []
        self.context_stack = []

    def update_context(self, user_input, gpt_response):
        """Update conversation context with new information"""
        # Extract entities and intents from the interaction
        entities = self.extract_entities(user_input)
        intent = self.classify_intent(user_input)

        # Update conversation state
        self.conversation_state.update({
            'last_user_input': user_input,
            'last_gpt_response': gpt_response,
            'current_intent': intent,
            'entities': entities,
            'timestamp': datetime.now().isoformat()
        })

    def extract_entities(self, text):
        """Extract named entities from text"""
        # Implementation would use NER models or regex patterns
        entities = {}
        # Example: extract locations, objects, times, etc.
        return entities

    def classify_intent(self, text):
        """Classify user intent"""
        # Implementation would use intent classification models
        return "unknown"
```

## Privacy and Safety Considerations

When implementing GPT integration with robots, several privacy and safety considerations must be addressed:

1. **Data Privacy**: Ensure that conversations are handled securely and not stored unnecessarily
2. **Safety Constraints**: Implement safety checks to prevent the robot from executing dangerous actions
3. **Context Limitations**: Be aware of the LLM's limitations in understanding complex physical situations
4. **Fallback Mechanisms**: Provide manual override and fallback behaviors when needed

## Performance Optimization

### Caching and Context Management
```python
class OptimizedGPTInterface:
    def __init__(self, max_context_length=4096):
        self.max_context_length = max_context_length
        self.context_cache = []
        self.response_cache = {}

    def trim_context(self, context):
        """Trim context to fit within token limits"""
        # Implementation to trim conversation history while preserving important context
        pass
```

## Cross-Module References

For more information about related topics, see:
- Module 1: Bridging Python Agents with RCLPY for ROS integration
- Module 1: ROS 2 Architecture for Humanoids for communication patterns
- Module 1: ROS 2 Nodes, Topics, and Services for messaging systems
- Module 2: Gazebo Simulation Setup for testing conversational systems in simulation
- Module 2: Physics and Sensor Simulation for environment awareness
- Module 3: Perception and Manipulation for object interaction
- Module 3: Reinforcement Learning Control for adaptive behavior
- Module 3: Isaac SDK and Sim Overview for advanced simulation integration
- Module 4: Cognitive Planning for LLM-to-ROS translation
- Module 4: Speech Recognition with Whisper for audio processing
- Module 4: Capstone Project: Autonomous Humanoid for complete system integration
